{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f37d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12669 entries, 16 to 98878\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   review_id                12669 non-null  object\n",
      " 1   order_id                 12669 non-null  object\n",
      " 2   review_score             12669 non-null  int64 \n",
      " 3   review_comment_title     12669 non-null  object\n",
      " 4   review_comment_message   12669 non-null  object\n",
      " 5   review_creation_date     12669 non-null  object\n",
      " 6   review_answer_timestamp  12669 non-null  object\n",
      " 7   days                     12669 non-null  int64 \n",
      " 8   bucket                   12669 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 989.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, time, random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from deep_translator import GoogleTranslator\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "order_review_wide = pd.read_csv(\"../../processed/order_review_wide.csv\")\n",
    "cond1 = order_review_wide['review_comment_message']!='U'\n",
    "cond2 = order_review_wide['review_score']<=3\n",
    "cond3 = order_review_wide['days'] > -1 \n",
    "bad_review_data = order_review_wide[cond1 & cond2 & cond3].copy() \n",
    "bad_review_data.dropna(subset='bucket', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CSV = Path('/wordcloud_csv')\n",
    "SAVE_CSV.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "THREADS = 6\n",
    "BATCH_SIZE = 1000\n",
    "MAX_RETRY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_translate(text):\n",
    "    for attempt in range(MAX_RETRY):\n",
    "        try:\n",
    "            translator = GoogleTranslator(source='pt', target='zh-CN')\n",
    "            return translator.translate(text)\n",
    "        except Exception as e:\n",
    "            time.sleep(random.uniform(1,3))\n",
    "    return None\n",
    "\n",
    "def translate_batch(batch_df, batch_id):\n",
    "    rows = []\n",
    "    with ThreadPoolExecutor(max_workers=THREADS) as executor:\n",
    "        futures = {executor.submit(safe_translate, row['review_comment_message']): row for _, row in batch_df.iterrows()}\n",
    "        for fut in as_completed(futures):\n",
    "            row = futures[fut]\n",
    "            res = fut.result()\n",
    "            if res:\n",
    "                rows.append({\n",
    "                    'order_id': row['order_id'],\n",
    "                    'bucket': row['bucket'],\n",
    "                    'original': row['review_comment_message'],\n",
    "                    'translated': res\n",
    "                })\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(SAVE_CSV / f'translated_part_{batch_id}.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\" 第 {batch_id} 批完成，共 {len(out)} 条\")\n",
    "    return out\n",
    "\n",
    "for i in range(0, len(bad_review_data), BATCH_SIZE):\n",
    "    batch = bad_review_data.iloc[i:i+BATCH_SIZE]\n",
    "    batch_id = i // BATCH_SIZE + 1\n",
    "    print(f\"\\n正在翻译第 {batch_id} 批，共 {len(batch)} 条...\")\n",
    "    translate_batch(batch, batch_id)\n",
    "    time.sleep(random.uniform(2,5))  # 防封短暂停\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d23f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. 读取所有分批翻译文件\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m files = \u001b[38;5;28msorted\u001b[39m(\u001b[43mglob\u001b[49m.glob(\u001b[38;5;28mstr\u001b[39m(SAVE_CSV / \u001b[33m'\u001b[39m\u001b[33mtranslated_part_*.csv\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m共检测到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 个翻译结果文件\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 2. 合并为一个 DataFrame\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 读取所有分批翻译文件\n",
    "files = sorted(glob.glob(str(SAVE_CSV / 'translated_part_*.csv')))\n",
    "print(f\"共检测到 {len(files)} 个翻译结果文件\")\n",
    "\n",
    "# 2. 合并为一个 DataFrame\n",
    "df_all = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)\n",
    "\n",
    "# 3. 数据清洗\n",
    "df_all.drop_duplicates(subset=['order_id'], inplace=True)\n",
    "df_all.dropna(subset=['translated'], inplace=True)\n",
    "\n",
    "print(f\" 合并后共 {len(df_all)} 条评论\")\n",
    "df_all.head()\n",
    "\n",
    "# 定义关键词\n",
    "keywords = ['未收到', '慢', '延迟','未发货']\n",
    "\n",
    "# 定义计算函数\n",
    "def kw_rate(g):\n",
    "    total = len(g)\n",
    "    out = {}\n",
    "    for kw in keywords:\n",
    "        out[kw] = round(g['translated'].str.contains(kw, na=False).mean() * 100, 2)\n",
    "    out['n_reviews'] = total\n",
    "    return pd.Series(out)\n",
    "\n",
    "# 分组统计\n",
    "bucket_stats = df_all.groupby('bucket').apply(kw_rate).reset_index()\n",
    "\n",
    "bucket_stats.to_csv(SAVE_CSV / \"评论关键词频率表.csv\")\n",
    "print(bucket_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
